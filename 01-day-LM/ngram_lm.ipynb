{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngram-lm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b9391e6dd7e4f78bc42a05afb206b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de50cd5acf8640aab7881a43ef73ff70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2e6fd459ded497fbf3e70ceda2b75a9",
              "IPY_MODEL_7c7745b2cea64946a6760811e365b016"
            ]
          }
        },
        "de50cd5acf8640aab7881a43ef73ff70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2e6fd459ded497fbf3e70ceda2b75a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eeae7f9e7a274d9a91221f023fefe509",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecbd307b648d4c9382d7cab57771b0fb"
          }
        },
        "7c7745b2cea64946a6760811e365b016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a527559a92e24ac4b137befa17cc6794",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107790/? [00:07&lt;00:00, 13709.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c0eeb1564994bae91b9094f60ba75fb"
          }
        },
        "eeae7f9e7a274d9a91221f023fefe509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecbd307b648d4c9382d7cab57771b0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a527559a92e24ac4b137befa17cc6794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c0eeb1564994bae91b9094f60ba75fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3a630bf4aab44788565ab1c74a00513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab6a9990dd6c47f6950fe998ebd46fb0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81b23a3cd3fe4cb6ab5f3e87f0245ded",
              "IPY_MODEL_36449e571a184ff79026c694090d399b"
            ]
          }
        },
        "ab6a9990dd6c47f6950fe998ebd46fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81b23a3cd3fe4cb6ab5f3e87f0245ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12ce958aaa064cfc903359590ec9752a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3a43b1c424949688277a7564887e528"
          }
        },
        "36449e571a184ff79026c694090d399b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa872070e05b46aa82777aa17f58dcb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 15172/? [01:28&lt;00:00, 170.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62db310239e04b73a38b42a343f9f16f"
          }
        },
        "12ce958aaa064cfc903359590ec9752a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3a43b1c424949688277a7564887e528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa872070e05b46aa82777aa17f58dcb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62db310239e04b73a38b42a343f9f16f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kabongosalomon/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxqqEn-2di_D",
        "colab_type": "text"
      },
      "source": [
        "# Language Modeling\n",
        "\n",
        "### Goal: compute a probabilty distribution over all possible sentences:\n",
        "\n",
        "\n",
        "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
        "\n",
        "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
        "\n",
        "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
        "\n",
        "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
        "\n",
        "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvtQ0wJJdi_H",
        "colab_type": "text"
      },
      "source": [
        "# N-gram language model\n",
        "\n",
        "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
        "\n",
        "### Given a sequence of words $w$, we want to compute\n",
        "\n",
        "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
        "\n",
        "### Where $w_i$ is the i-th word of the sequence.\n",
        "\n",
        "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
        "\n",
        "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16hxXNq_di_L",
        "colab_type": "text"
      },
      "source": [
        "## N-gram Probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUDGU_Jtdi_O",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS6ukvypdi_Q",
        "colab_type": "text"
      },
      "source": [
        "## Bigram Probabilities\n",
        "\n",
        "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMYxnO4kdi_S",
        "colab_type": "code",
        "colab": {},
        "outputId": "28b9aaea-08fd-4ebd-9de7-6734d4923b14"
      },
      "source": [
        "# !python -m spacy download en_core_web_sm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 981kB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25lerror\n",
            "    Complete output from command /home/kulikov/venv/ammi/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-1w10f_lh/en-core-web-sm/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-l0j0sy9u-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/kulikov/venv/ammi/include/site/python3.5/en-core-web-sm:\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib\n",
            "    creating build/lib/en_core_web_sm\n",
            "    copying en_core_web_sm/__init__.py -> build/lib/en_core_web_sm\n",
            "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/tokenizer -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/accuracy.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/meta.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0\n",
            "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/tagger/tag_map -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/tagger\n",
            "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/lower_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/upper_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/moves -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/parser/tok2vec_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/parser\n",
            "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/cfg -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/lower_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/upper_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/moves -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/ner/tok2vec_model -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/ner\n",
            "    creating build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/strings.json -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/key2row -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/vectors -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
            "    copying en_core_web_sm/en_core_web_sm-2.0.0/vocab/lexemes.bin -> build/lib/en_core_web_sm/en_core_web_sm-2.0.0/vocab\n",
            "    copying en_core_web_sm/meta.json -> build/lib/en_core_web_sm\n",
            "    running install_lib\n",
            "    creating /home/kulikov/venv/ammi/lib/python3.5/site-packages/en_core_web_sm\n",
            "    error: could not create '/home/kulikov/venv/ammi/lib/python3.5/site-packages/en_core_web_sm': Permission denied\n",
            "    \n",
            "    ----------------------------------------\n",
            "\u001b[31mCommand \"/home/kulikov/venv/ammi/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-1w10f_lh/en-core-web-sm/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-l0j0sy9u-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/kulikov/venv/ammi/include/site/python3.5/en-core-web-sm\" failed with error code 1 in /tmp/pip-build-1w10f_lh/en-core-web-sm/\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnmIvmg9d4BV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "d4e28b20-dc0f-454f-8ec5-245dc48d2df7"
      },
      "source": [
        "! git clone https://github.com/kyunghyuncho/ammi-2019-nlp.git\n",
        "%cd ammi-2019-nlp\n",
        "\n",
        "\n",
        "# some package to install \n",
        "\n",
        "!pip install altair\n",
        "!pip install pygtrie"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ammi-2019-nlp'...\n",
            "remote: Enumerating objects: 812, done.\u001b[K\n",
            "remote: Total 812 (delta 0), reused 0 (delta 0), pack-reused 812\u001b[K\n",
            "Receiving objects: 100% (812/812), 186.47 MiB | 30.54 MiB/s, done.\n",
            "Resolving deltas: 100% (543/543), done.\n",
            "/content/ammi-2019-nlp/ammi-2019-nlp\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.18.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n",
            "Collecting pygtrie\n",
            "  Downloading https://files.pythonhosted.org/packages/18/41/2e5cefc895a32d9ca0f3574bd0df09e53a697023579a93582bedc4eeac4d/pygtrie-2.3.2.tar.gz\n",
            "Building wheels for collected packages: pygtrie\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.3.2-cp36-none-any.whl size=18867 sha256=2b7a3d6121dbccaeaf95bc629d29f5ed5bae9df5f4ccd89832f3117a6092f525\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/3c/2d28c8ac56cda265d0c16ca129f50e5c3526f49a7fbe224cd9\n",
            "Successfully built pygtrie\n",
            "Installing collected packages: pygtrie\n",
            "Successfully installed pygtrie-2.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJJ_EIxNdi_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('utils/')\n",
        "from utils import ngram_utils as ngram_utils\n",
        "import utils.global_variables as gl\n",
        "import torch\n",
        "import random\n",
        "from utils.ngram_utils import NgramLM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H20pktPiA63a",
        "outputId": "6a55e168-8eb2-4a21-d81f-a5bec80340f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb291f59110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI7M81LJdi_n",
        "colab_type": "text"
      },
      "source": [
        "### Load Data from .txt Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TWeIoEQdi_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data from .txt files and create lists of reviews\n",
        "\n",
        "train_data = []\n",
        "# create a list of all the reviews \n",
        "with open('../data/amazon_train.txt', 'r') as f:\n",
        "    train_data = [review for review in f.read().split('\\n') if review]\n",
        "    \n",
        "valid_data = []\n",
        "# create a list of all the reviews \n",
        "with open('../data/amazon_valid.txt', 'r') as f:\n",
        "    valid_data = [review for review in f.read().split('\\n') if review]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ95rlGndi_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(train_data), len(train_data), \\\n",
        "# type(train_data[0]), len(train_data[0]), \\\n",
        "# type(train_data[0][0]), len(train_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCY9kNxdi_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "74303313-b856-4780-be79-c9fa2c4008c6"
      },
      "source": [
        "train_data[0], train_data[0][0], len(train_data)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
              " 't',\n",
              " 22288)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFIqO0lCdi_8",
        "colab_type": "text"
      },
      "source": [
        "### Process the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPIvTKQTdi_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "1b9391e6dd7e4f78bc42a05afb206b54",
            "de50cd5acf8640aab7881a43ef73ff70",
            "b2e6fd459ded497fbf3e70ceda2b75a9",
            "7c7745b2cea64946a6760811e365b016",
            "eeae7f9e7a274d9a91221f023fefe509",
            "ecbd307b648d4c9382d7cab57771b0fb",
            "a527559a92e24ac4b137befa17cc6794",
            "7c0eeb1564994bae91b9094f60ba75fb",
            "c3a630bf4aab44788565ab1c74a00513",
            "ab6a9990dd6c47f6950fe998ebd46fb0",
            "81b23a3cd3fe4cb6ab5f3e87f0245ded",
            "36449e571a184ff79026c694090d399b",
            "12ce958aaa064cfc903359590ec9752a",
            "d3a43b1c424949688277a7564887e528",
            "fa872070e05b46aa82777aa17f58dcb0",
            "62db310239e04b73a38b42a343f9f16f"
          ]
        },
        "outputId": "64487615-9dc0-4030-d488-7bc4e63dfef3"
      },
      "source": [
        "# Tokenize the Datasets\n",
        "# TODO: this takes a really long time !! why?\n",
        "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
        "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b9391e6dd7e4f78bc42a05afb206b54",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3a630bf4aab44788565ab1c74a00513",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yviPk12ydjAE",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the tokenized data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i76CnACidjAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "c42ed151-474a-4340-fc35-85e4ec9c3b30"
      },
      "source": [
        "# # Number of All Tokens\n",
        "# len(all_tokens_train), all_tokens_train[0], \\\n",
        "len(train_data_tokenized), train_data_tokenized[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107790,\n",
              " ['this',\n",
              "  'is',\n",
              "  'a',\n",
              "  'great',\n",
              "  'tutu',\n",
              "  'and',\n",
              "  'at',\n",
              "  'a',\n",
              "  'really',\n",
              "  'great',\n",
              "  'price',\n",
              "  '.'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYkh_VtxdjAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
        "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5OZtWUYdjAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0564415e-727b-4c91-9cd7-321b462b86ff"
      },
      "source": [
        "train_ngram_lm.trie_ngram['./<eos>/<eos>']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBWEHlCRdjAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a916c029-52f0-4e3b-911f-70241e3bf28f"
      },
      "source": [
        "train_ngram_lm.n, train_ngram_lm.frac_vocab"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 0.9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWd_yfI3djAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6da95a26-e46b-42f9-c3bd-b97f7badce1f"
      },
      "source": [
        "valid_ngram_lm.id2token[0:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<sos>', '<eos>', '.', 'the', 'i', ',', 'and', 'a', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_fl24SfdjAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa29f0cf-416d-4176-a18e-639f7243f388"
      },
      "source": [
        "valid_ngram_lm.token2id['<unk>'], valid_ngram_lm.token2id['<sos>'], valid_ngram_lm.token2id['the']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL0jmDu2djAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0a643e48-f433-4983-dcb2-3f2a1acb3ac5"
      },
      "source": [
        "valid_ngram_lm.vocab_ngram[:10], valid_ngram_lm.count_ngram[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', '<sos>', 'the'),\n",
              "  ('<sos>', '<sos>', 'it'),\n",
              "  ('!', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'this'),\n",
              "  ('it', \"'\", 's'),\n",
              "  ('.', '.', '.'),\n",
              "  ('.', '.', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'they')),\n",
              " (13625, 3635, 1425, 1100, 1049, 762, 687, 655, 580, 569))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fSUBHvVdjAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "7bdd8505-5537-4619-f760-d24378eb1239"
      },
      "source": [
        "valid_ngram_lm.vocab_bigram[:10], valid_ngram_lm.count_bigram[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>'),\n",
              "  ('<sos>', 'i'),\n",
              "  ('<sos>', 'the'),\n",
              "  (\"'\", 't'),\n",
              "  (\"'\", 's'),\n",
              "  ('.', '.'),\n",
              "  ('<sos>', 'it'),\n",
              "  ('!', '<eos>'),\n",
              "  (',', 'and'),\n",
              "  (',', 'but')),\n",
              " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTxWG5jbdjA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "dd340be7-24ff-49bc-c7c7-fc95b2fe9626"
      },
      "source": [
        "valid_ngram_lm.vocab_unigram[:10], valid_ngram_lm.count_unigram[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.',),\n",
              "  ('the',),\n",
              "  ('i',),\n",
              "  (',',),\n",
              "  ('and',),\n",
              "  ('a',),\n",
              "  ('it',),\n",
              "  ('to',),\n",
              "  (\"'\",),\n",
              "  ('is',)),\n",
              " (14883, 9408, 8000, 7525, 6226, 5774, 5085, 4550, 3816, 3695))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9Gc7x6djA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "2e2979c6-2752-440f-fa5a-4ce1eb86862b"
      },
      "source": [
        "valid_ngram_lm.vocab_prev_ngram[:10], valid_ngram_lm.count_prev_ngram[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>'),\n",
              "  ('<sos>', 'i'),\n",
              "  ('<sos>', 'the'),\n",
              "  (\"'\", 't'),\n",
              "  (\"'\", 's'),\n",
              "  ('.', '.'),\n",
              "  ('<sos>', 'it'),\n",
              "  ('!', '<eos>'),\n",
              "  (',', 'and'),\n",
              "  (',', 'but')),\n",
              " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyzIGQkVdjA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "3958f901-6297-4feb-c3e4-7bcc87e862be"
      },
      "source": [
        "valid_ngram_lm.id2token_ngram[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', '<eos>', '<eos>'),\n",
              " ('<sos>', '<sos>', 'i'),\n",
              " ('<sos>', '<sos>', 'the'),\n",
              " ('<sos>', '<sos>', 'it'),\n",
              " ('!', '<eos>', '<eos>'),\n",
              " ('<sos>', '<sos>', 'this'),\n",
              " ('it', \"'\", 's'),\n",
              " ('.', '.', '.'),\n",
              " ('.', '.', '<eos>'),\n",
              " ('<sos>', '<sos>', 'they')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghKQ39sMdjBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b278847-46da-4855-fe4a-0d3cb5f0a495"
      },
      "source": [
        "valid_ngram_lm.token2id_ngram[('.', '<eos>', '<eos>')], valid_ngram_lm.token2id_ngram[('.', '.', '<eos>')]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsnRuz-tdjBL",
        "colab_type": "text"
      },
      "source": [
        "#### Build the Vocabulary \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJwZj8HzdjBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a138274-8e36-4464-a632-9d114b86f7aa"
      },
      "source": [
        "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
        "print('Word vocabulary size: {} words'.format(len(train_ngram_lm.token2id)))        "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word vocabulary size: 20806 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdrxatCzdjBS",
        "colab_type": "text"
      },
      "source": [
        "### CORPUS ANALYSIS (Train + Valid Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxgpyhGzdjBU",
        "colab_type": "text"
      },
      "source": [
        "#### Number of Tokens in the Corpus Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NPj8z5djBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "688d5dc4-6698-463e-b2b1-58b31fe079c6"
      },
      "source": [
        "print(\"Number of All Tokens \", len(all_tokens_train))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of All Tokens  1623446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WNQyxpLdjBZ",
        "colab_type": "text"
      },
      "source": [
        "#### Number of Sentences in the Train Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he4R7QrYdjBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19e239c3-9eb5-4138-b3d7-679960217880"
      },
      "source": [
        "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sentences  107790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YzK-J-7djBf",
        "colab_type": "text"
      },
      "source": [
        "## N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cj0FKXpdjBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 3 # trigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P1rNcPodjBm",
        "colab_type": "text"
      },
      "source": [
        "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAT8lahndjBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_padded = train_ngram_lm.padded_data\n",
        "train_ngram = train_ngram_lm.ngram_data\n",
        "vocab_ngram = train_ngram_lm.vocab_ngram\n",
        "count_ngram = train_ngram_lm.count_ngram "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7xtb82DdjBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "7f6a432a-3626-4bd6-9b4c-0ad343d7d764"
      },
      "source": [
        "train_padded[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " '<sos>',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'tutu',\n",
              " 'and',\n",
              " 'at',\n",
              " 'a',\n",
              " 'really',\n",
              " 'great',\n",
              " 'price',\n",
              " '.',\n",
              " '<eos>',\n",
              " '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FivzoepYdjB3",
        "colab_type": "text"
      },
      "source": [
        "### Function for finding all N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27_jPzjqdjB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "91bb8bc8-f2a6-424f-8da5-082e96afd7db"
      },
      "source": [
        "train_ngram[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<sos>', '<sos>', 'this'),\n",
              " ('<sos>', 'this', 'is'),\n",
              " ('this', 'is', 'a'),\n",
              " ('is', 'a', 'great'),\n",
              " ('a', 'great', 'tutu'),\n",
              " ('great', 'tutu', 'and'),\n",
              " ('tutu', 'and', 'at'),\n",
              " ('and', 'at', 'a'),\n",
              " ('at', 'a', 'really'),\n",
              " ('a', 'really', 'great'),\n",
              " ('really', 'great', 'price'),\n",
              " ('great', 'price', '.'),\n",
              " ('price', '.', '<eos>'),\n",
              " ('.', '<eos>', '<eos>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XesU3dPMdjB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1fbc68b-9f50-4cf4-b833-4c48c09a6691"
      },
      "source": [
        "vocab_ngram[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('.', '<eos>', '<eos>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaYHnCm3djCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c76a9757-cbbb-4e0e-f6d9-395c02963881"
      },
      "source": [
        "count_ngram[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ymlU7uPdjCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trie_ngram = train_ngram_lm.trie_ngram\n",
        "# trie_ngram\n",
        "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhV0zxudjCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f194c542-a018-4db8-dc75-65727ad16f70"
      },
      "source": [
        "trie_ngram['./<eos>/<eos>']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zylq9__vdjCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2token = train_ngram_lm.id2token\n",
        "token2id = train_ngram_lm.token2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9uR3J7djCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2token_ngram = train_ngram_lm.id2token_ngram\n",
        "token2id_ngram = train_ngram_lm.token2id_ngram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjl8FJbldjCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a5fb1326-0d7b-44b1-efe4-269dd2fa5f8e"
      },
      "source": [
        "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
        "random_token = id2token_ngram[random_token_id]\n",
        "\n",
        "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
        "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token id 664353 ; token ('costly', 'swiss', 'watch')\n",
            "Token ('costly', 'swiss', 'watch'); token id 664353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgSpb0f8djCk",
        "colab_type": "text"
      },
      "source": [
        "### Ngram Count & Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teH4Uv3bdjCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQ5Z-m-djCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b3767904-1e74-4a62-9938-93b5598e00fc"
      },
      "source": [
        "vocab_ngram[:10], count_ngram[:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((('.', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', '<sos>', 'the'),\n",
              "  ('!', '<eos>', '<eos>'),\n",
              "  ('<sos>', '<sos>', 'they'),\n",
              "  ('<sos>', '<sos>', 'it'),\n",
              "  ('.', '.', '.'),\n",
              "  ('<sos>', '<sos>', 'this'),\n",
              "  ('<sos>', '<sos>', 'these'),\n",
              "  ('.', '.', '<eos>')),\n",
              " (96175, 26986, 9197, 8152, 6376, 5373, 4693, 4189, 3941, 3876))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA33Aqy2djCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENAiUwVEdjC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c48d311-88fd-42d7-fa47-707f62efbcbe"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
        "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
        "\n",
        "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
        "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
        "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
        "\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
        "\n",
        "c, p, p1, p2, p3, sum(pd)#, pd"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0.04, 0.04, 0.04, 0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVbchPEdjC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ed5b9f6-4639-4275-decf-ba049270798a"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
        "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
        "\n",
        "c, p, sum(pd)#, pd "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 0.06521739130434782, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbpcMofodjDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "263cd8dc-6ed3-4861-b2d2-099af6ccef90"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
        "\n",
        "c"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4KS70zkdjDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2415a4cd-c5ae-4e0e-98d2-44fea772fec3"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
        "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96175, 1.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpwGPhg8djDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dcce8ac-c425-4383-e470-3c5fb2371205"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
        "\n",
        "c"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pXTepy_djDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd82e71f-d091-4d85-ba62-d54285d17c37"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
        "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0.9999999999999897)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik55OVfKdjDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abfc1e13-9129-4bfb-c2a7-10e3b6eeb3f8"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
        "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(266, 0.09761467889908257, 1.0000000000000142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNmsouXmdjDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "197f3b1f-f6d0-44f4-b0a4-c568186a145a"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
        "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 0.9032258064516129, 1.0000000000000657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiIETwaPdjDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60707ed8-68f3-43cd-dda5-8bd4c5c561ee"
      },
      "source": [
        "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
        "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
        "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
        "\n",
        "c, p, sum(pd)#, pd"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 1.0000000000000657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p62PNunYdjDg",
        "colab_type": "text"
      },
      "source": [
        "## Add-One Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNbNhB1NdjDh",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ozhaUc3djDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8533ca2-f98e-4064-9145-33f79eb1121a"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
        "p"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.806305873305777e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwVGT7QVdjDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1cd75fa-9568-49d6-b291-453ecd1fca10"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
        "p"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.504098729844158e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52O-R3d_djDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e03be2a9-2f25-4291-b1b0-c6f83a7077ff"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
        "p"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004323934780650392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilot3KlpdjDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aec1c998-69aa-4053-9a32-fedfa86cb827"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
        "p"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001918281220026856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDCJgKxpdjDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e976b0e1-3641-415d-d8b0-429f9b9e7ce3"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
        "p"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0013917550511110045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFzSt_etdjD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ded111d-4654-4cd8-a94d-ee9c19f37879"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
        "p"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8221506056539096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02yJEakjdjEA",
        "colab_type": "text"
      },
      "source": [
        "## Additive Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq6-DIgqdjEB",
        "colab_type": "text"
      },
      "source": [
        "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EGUDv9TdjEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abad1261-48a6-4093-aeec-20b97868c670"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.806305873305777e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4DFUZxYdjEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45bb4d1c-58c5-47ef-ba8e-f8cd5a26fb22"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.237647258242224e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uKbaJH2djEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62379fe2-74a6-4bf2-f71e-fcf021fa2d7f"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008093906263242648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXmQeLBPdjET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12669fe3-564b-4e23-e7dc-35909e045061"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00033496028328069673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atC1E0aWdjEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7079f8e0-7b83-407b-d7ea-429f91d325b7"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0027314548591144336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5rzN2MYdjEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7ede003-36be-451d-df6b-abfe123960ad"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
        "p"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9023954287001069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBHE7VmodjEp",
        "colab_type": "text"
      },
      "source": [
        "### Changing the Parameter $\\delta$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwRKDDpVdjEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1479e8b8-d49a-4940-d59f-51d52ca08c47"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
        "p"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9788256343658784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgnMbDwNdjEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "682161f1-972c-4f5a-de81-fd2c0a6128d0"
      },
      "source": [
        "# arge delta --> closer to add-one smoothing (0.58)\n",
        "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
        "p"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370371208455323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwyOVSIVdjE1",
        "colab_type": "text"
      },
      "source": [
        "## Linear Interpolation Smoothing (Jelinek-Mercer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHojDm4DdjE2",
        "colab_type": "text"
      },
      "source": [
        "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu12m16ddjE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8d9b21d-97f9-41c4-8e38-4748387207aa"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA-nj4dydjFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7012e86f-7188-43ab-fe1b-12f9afd37cc1"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c_71Rd6djFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63c5191e-ae41-433d-ac57-c938f41a9c35"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.054441260744985676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR9_27y0djFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c62ba47a-6ba5-443a-f61b-679c0ac7b2d7"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.052173913043478265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK8lnYVOdjFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9af3aa00-0d77-44ec-e583-a20f7df16e9c"
      },
      "source": [
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7225806451612904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bWIN0bDdjFU",
        "colab_type": "text"
      },
      "source": [
        "### Changing the Parameter $\\alpha$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbtx8jQwdjFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c94ab906-45bc-480a-fc82-8121f849994c"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
        "p"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ-6hj5WdjFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebcbdd46-c5d6-420b-b7fc-9bb2270f23e0"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
        "p"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojvd5opOdjFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61c6524b-4b2e-42be-c0dc-685a49baa004"
      },
      "source": [
        "# small delta --> closer to no smoothing  (1.0)\n",
        "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
        "p"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVhjNbfQdjFh",
        "colab_type": "text"
      },
      "source": [
        "## Linear Interpolation with Absolute Discounting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhHWK8UQdjFi",
        "colab_type": "text"
      },
      "source": [
        "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
        "\n",
        "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
        "\n",
        "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
        "\n",
        "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
        "\n",
        "\n",
        "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
        "\n",
        "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
        "\n",
        "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
        "\n",
        "### V is the number of words in the vocabulary\n",
        "\n",
        "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukOamJGDdjFj",
        "colab_type": "text"
      },
      "source": [
        "### Remember to check that probabilities sum up to one:\n",
        "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msboRMuGdjFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y = \"m\"\n",
        "# x = \"'\"\n",
        "\n",
        "# z = train_ngram_lm.get_p_bi(y, x)\n",
        "# z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7mFlXs1djFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "69035b6c-1dbd-413e-8b96-15f5d748967d"
      },
      "source": [
        "train_ngram[:3]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('<sos>', '<sos>', 'this'),\n",
              "  ('<sos>', 'this', 'is'),\n",
              "  ('this', 'is', 'a'),\n",
              "  ('is', 'a', 'great'),\n",
              "  ('a', 'great', 'tutu'),\n",
              "  ('great', 'tutu', 'and'),\n",
              "  ('tutu', 'and', 'at'),\n",
              "  ('and', 'at', 'a'),\n",
              "  ('at', 'a', 'really'),\n",
              "  ('a', 'really', 'great'),\n",
              "  ('really', 'great', 'price'),\n",
              "  ('great', 'price', '.'),\n",
              "  ('price', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')],\n",
              " [('<sos>', '<sos>', 'it'),\n",
              "  ('<sos>', 'it', 'doesn'),\n",
              "  ('it', 'doesn', \"'\"),\n",
              "  ('doesn', \"'\", 't'),\n",
              "  (\"'\", 't', 'look'),\n",
              "  ('t', 'look', 'cheap'),\n",
              "  ('look', 'cheap', 'at'),\n",
              "  ('cheap', 'at', 'all'),\n",
              "  ('at', 'all', '.'),\n",
              "  ('all', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')],\n",
              " [('<sos>', '<sos>', 'i'),\n",
              "  ('<sos>', 'i', \"'\"),\n",
              "  ('i', \"'\", 'm'),\n",
              "  (\"'\", 'm', 'so'),\n",
              "  ('m', 'so', 'glad'),\n",
              "  ('so', 'glad', 'i'),\n",
              "  ('glad', 'i', 'looked'),\n",
              "  ('i', 'looked', 'on'),\n",
              "  ('looked', 'on', 'amazon'),\n",
              "  ('on', 'amazon', 'and'),\n",
              "  ('amazon', 'and', 'found'),\n",
              "  ('and', 'found', 'such'),\n",
              "  ('found', 'such', 'an'),\n",
              "  ('such', 'an', 'affordable'),\n",
              "  ('an', 'affordable', 'tutu'),\n",
              "  ('affordable', 'tutu', 'that'),\n",
              "  ('tutu', 'that', 'isn'),\n",
              "  ('that', 'isn', \"'\"),\n",
              "  ('isn', \"'\", 't'),\n",
              "  (\"'\", 't', 'made'),\n",
              "  ('t', 'made', 'poorly'),\n",
              "  ('made', 'poorly', '.'),\n",
              "  ('poorly', '.', '<eos>'),\n",
              "  ('.', '<eos>', '<eos>')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU3dGDhvdjFr",
        "colab_type": "text"
      },
      "source": [
        "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOIJ57c1djFt",
        "colab_type": "text"
      },
      "source": [
        "### Bigram LM\n",
        "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mexY1DDedjFu",
        "colab_type": "text"
      },
      "source": [
        "## Likelihood of a Sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWTNjYEndjFv",
        "colab_type": "text"
      },
      "source": [
        "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
        "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
        "\n",
        "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxkwliuodjFw",
        "colab_type": "text"
      },
      "source": [
        "### Score Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ychvcedjF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b0cc0812-6c22-40ec-b105-6a65e0729611"
      },
      "source": [
        "n = 3\n",
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss =  train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 5.127565397867753e+77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1YiQ7NdjF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f421ba1e-5004-4a3b-d093-efd5be369501"
      },
      "source": [
        "n = 3\n",
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.2919413175965264e-13, 6.675591427844734)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh3r0dmFdjGB",
        "colab_type": "text"
      },
      "source": [
        "## Sentence Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc7u0PTedjGB",
        "colab_type": "text"
      },
      "source": [
        "#### No Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-zfW8YxdjGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "21c5a4a4-88e7-4178-b7c8-59b707b86d76"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "i was\n",
            "i was disappointed\n",
            "i was disappointed because\n",
            "i was disappointed because i\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i was disappointed because i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPBXg8Q5djGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0964bc40-9117-48db-89a8-a24c8809ade3"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "watch\n",
            "watch .\n",
            "watch . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'watch . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tobGWzCOdjGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ffb91888-6399-4ba6-c851-e255dbd901f8"
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it\n",
            "it is\n",
            "it is .\n",
            "it is . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it is . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgk1iYPPdjGS",
        "colab_type": "text"
      },
      "source": [
        "#### With Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW914GF5djGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4002a091-6bb8-45ac-f264-1e357da9d4ea"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "french\n",
            "french word\n",
            "french word ,\n",
            "french word , i\n",
            "french word , i was\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'french word , i was'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL9u2zTudjGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6721aefd-2e5e-4940-fc9d-243307cb3368"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colour\n",
            "colour is\n",
            "colour is not\n",
            "colour is not the\n",
            "colour is not the six\n",
            "colour is not the six pack\n",
            "colour is not the six pack of\n",
            "colour is not the six pack of paracetamol\n",
            "colour is not the six pack of paracetamol and\n",
            "colour is not the six pack of paracetamol and toothpaste\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'colour is not the six pack of paracetamol and toothpaste'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUaruew5djGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "646b05f6-b22c-4041-9314-52ba061ee06b"
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "straps\n",
            "straps .\n",
            "straps . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'straps . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phekgfUxdjGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0296b7d2-9941-4387-ea6b-800a52fdfbb7"
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'worst'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bra\n",
            "bra i\n",
            "bra i '\n",
            "bra i ' m\n",
            "bra i ' m sure\n",
            "bra i ' m sure hand\n",
            "bra i ' m sure hand washing\n",
            "bra i ' m sure hand washing and\n",
            "bra i ' m sure hand washing and treating\n",
            "bra i ' m sure hand washing and treating like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"bra i ' m sure hand washing and treating like\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ziM1QYdjGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a0b2983b-882f-469a-ddbe-2cb048f84090"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'best'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\n",
            "! !\n",
            "! ! <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'! ! <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yORVOmswdjGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b45fe430-13f6-4dcb-9bb7-d824554fb285"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('not', 'what'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it\n",
            "it needs\n",
            "it needs to\n",
            "it needs to change\n",
            "it needs to change them\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it needs to change them'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCjQwlZgdjGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5e873288-1d77-407d-8a25-4689dbd40149"
      },
      "source": [
        "num_tokens = 5\n",
        "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will'))\n",
        "generated_sentence\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "have\n",
            "have to\n",
            "have to wear\n",
            "have to wear at\n",
            "have to wear at a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have to wear at a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf86hkbOdjGu",
        "colab_type": "text"
      },
      "source": [
        "## Log-Likelihood (n-gram)\n",
        "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w72wZyQ1djGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En5Q53IydjG4",
        "colab_type": "text"
      },
      "source": [
        "## Perplexity\n",
        "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ8kPEaadjG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized, subsample=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmrH0crrdjG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c63eb4da-92f7-4472-ccec-77edf73e9e92"
      },
      "source": [
        "ppl_valid, ppl_train"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.054956118557522e+16, 785.4807625424293)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzV0AtlFdjHA",
        "colab_type": "text"
      },
      "source": [
        "### Interpolation Smoothing - varying N"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBvKdO4edjHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f44703a-af2d-47fd-9e81-4dcec91ffc62"
      },
      "source": [
        "# Interpolation Smoothing, N = 2\n",
        "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
        "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp2, ppl_train_no_interp2\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3198493286877.7236, 1789.0177288795328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocVRZ4ydjHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e98193b3-8885-4e05-a066-5cb6f36e95a1"
      },
      "source": [
        "# Interpolation Smoothing, N = 3\n",
        "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
        "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp3, ppl_train_no_interp3\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0631495430720946e+16, 867.0818779231803)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9qj1HqvdjHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72e94bc7-e97f-4fcd-d855-7fe76a198896"
      },
      "source": [
        "# Interpolation Smoothing, N = 5\n",
        "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
        "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp5, ppl_train_no_interp5\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.0922682216093802e+17, 205.1885172883371)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkH5iVTVdjHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing, N = 7\n",
        "train_ngram_lm_interp7 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation')\n",
        "valid_ngram_lm_interp7 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp7 = train_ngram_lm_interp7.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp7 = train_ngram_lm_interp7.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp7, ppl_train_no_interp7\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNGWbeW3djHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing, N = 10\n",
        "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
        "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
        "\n",
        "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp10, ppl_train_no_interp10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWCUgouvdjHO",
        "colab_type": "text"
      },
      "source": [
        "### Let's Compare Different Smoothing Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1LVH_Z_djHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No Smoothing\n",
        "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=7)\n",
        "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=7)\n",
        "\n",
        "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wb2HE25djHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.5)\n",
        "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.5)\n",
        "\n",
        "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive, ppl_train_no_additive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0IPMGydjHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.2)\n",
        "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.2)\n",
        "\n",
        "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qapJmUjBdjHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.8)\n",
        "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.8)\n",
        "\n",
        "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLrtAD2djHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Additive Smoothing\n",
        "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='add-one')\n",
        "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='add-one')\n",
        "\n",
        "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_add1, ppl_train_no_add1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w3-pLPRdjHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.2)\n",
        "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.2)\n",
        "\n",
        "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEbNdtd_djHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.8)\n",
        "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.8)\n",
        "\n",
        "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSHpM2g0djHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interpolation Smoothing\n",
        "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.5)\n",
        "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.5)\n",
        "\n",
        "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized, subsample=10)\n",
        "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized, subsample=10)\n",
        "\n",
        "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AflYQcHodjHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Discounted Interpolation Smoothing\n",
        "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
        "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
        "\n",
        "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
        "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
        "\n",
        "# ppl_valid_no_discount, ppl_train_no_discount\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSLbiNf1djHv",
        "colab_type": "text"
      },
      "source": [
        "### Additive Smoothing - varying N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPxvqZCkdjHw",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YMwKy8idjHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7OD14bxdjH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp3.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA5pIlKWdjH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp5.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1U4orhzdjH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp7.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp7.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M82TE3X9djH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_interp10.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grc0EuRbdjH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztQAXAXYdjID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['i', 'like', 'pandas']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAsUyH12djIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['i really like this watch']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92I54aMgdjII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = [['my wife really likes the color of this dress']]\n",
        "print(sentence)\n",
        "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
        "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
        "ps, ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPvPwl_JdjIJ",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG4Qb9HSdjIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIuOmuSfdjIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
        "generated_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWfN7bpndjIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp7.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTx4JlZVdjIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkLDKmGfdjIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 20\n",
        "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUdUD9APdjIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8fRJKZUdjIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = 10\n",
        "generated_sentence = train_ngram_lm_no_smoothing.generate_sentence(num_tokens)\n",
        "generated_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}